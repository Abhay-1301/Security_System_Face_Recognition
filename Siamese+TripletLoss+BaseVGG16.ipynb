{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras import backend as K\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "\n",
    "# Set the seed for reproducibility\n",
    "np.random.seed(0)\n",
    "\n",
    "# Define the triplet loss function\n",
    "# def triplet_loss(y_true, y_pred, alpha=0.2):\n",
    "#     anchor, positive, negative = y_pred[:, 0], y_pred[:, 1], y_pred[:, 2]\n",
    "#     pos_dist = tf.reduce_sum(tf.square(anchor - positive), axis=-1)\n",
    "#     neg_dist = tf.reduce_sum(tf.square(anchor - negative), axis=-1)\n",
    "#     loss = tf.maximum(pos_dist - neg_dist + alpha, 0.0)\n",
    "#     return tf.reduce_mean(loss)\n",
    "def triplet_loss(inputs, alpha=0.2):\n",
    "    anchor, positive, negative = inputs['anchor'], inputs['positive'], inputs['negative']\n",
    "\n",
    "    # Compute the distance between the anchor and positive embeddings\n",
    "    pos_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, positive)), axis=-1)\n",
    "\n",
    "    # Compute the distance between the anchor and negative embeddings\n",
    "    neg_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, negative)), axis=-1)\n",
    "\n",
    "    # Compute the triplet loss\n",
    "    basic_loss = tf.add(tf.subtract(pos_dist, neg_dist), alpha)\n",
    "    loss = tf.reduce_sum(tf.maximum(basic_loss, 0.0))\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "\n",
    "# Define the base model\n",
    "def get_base_model():\n",
    "    return VGG16(include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Define the siamese network model\n",
    "def get_siamese_model(base_model):\n",
    "    # Add a global average pooling layer\n",
    "    x = base_model.output\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "\n",
    "    # Define the input tensors\n",
    "    anchor_input = Input(shape=(224, 224, 3), name='anchor_input')\n",
    "    positive_input = Input(shape=(224, 224, 3), name='positive_input')\n",
    "    negative_input = Input(shape=(224, 224, 3), name='negative_input')\n",
    "\n",
    "    # Define new models with base_model input and x output\n",
    "    encoder = Model(inputs=base_model.input, outputs=x)\n",
    "\n",
    "    # Generate the encodings (output of the base model) for the anchor, positive, and negative images\n",
    "    encoded_anchor = encoder(anchor_input)\n",
    "    encoded_positive = encoder(positive_input)\n",
    "    encoded_negative = encoder(negative_input)\n",
    "\n",
    "    # Use Lambda layer to define custom layer for triplet loss\n",
    "    loss_layer = Lambda(triplet_loss, output_shape=(1,), name='triplet_loss')({\n",
    "        'anchor': encoded_anchor,\n",
    "        'positive': encoded_positive,\n",
    "        'negative': encoded_negative\n",
    "    })\n",
    "\n",
    "    # Define the siamese network model\n",
    "    siamese_model = Model(inputs=[anchor_input, positive_input, negative_input], outputs=loss_layer)\n",
    "\n",
    "    return siamese_model\n",
    "\n",
    "\n",
    "\n",
    "# Compile the siamese network model\n",
    "def compile_siamese_model(siamese_model):\n",
    "    optimizer = Adam(lr=0.0001)\n",
    "    siamese_model.compile(loss=triplet_loss, optimizer=optimizer)\n",
    "\n",
    "# Define the training data generator\n",
    "def get_train_data(train_dir):\n",
    "    datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "    # Get the image paths for each person\n",
    "    person_paths = []\n",
    "    for person_folder in os.listdir(train_dir):\n",
    "        person_path = os.path.join(train_dir, person_folder)\n",
    "        if os.path.isdir(person_path):\n",
    "            person_paths.append(person_path)\n",
    "\n",
    "    # Create pairs of anchor, positive, and negative images\n",
    "    anchor_images, positive_images, negative_images = [], [], []\n",
    "    for i in range(len(person_paths)):\n",
    "        for j in range(i+1, len(person_paths)):\n",
    "            person_i_images = os.listdir(person_paths[i])\n",
    "            person_j_images = os.listdir(person_paths[j])\n",
    "            for img_i in person_i_images:\n",
    "                for img_j in person_j_images:\n",
    "                    anchor_images.append(os.path.join(person_paths[i], img_i))\n",
    "                    positive_images.append(os.path.join(person_paths[j], img_j))\n",
    "                    negative_images.append(random.choice(person_paths[:i] + person_paths[i+1:j] + person_paths[j+1:]))\n",
    "\n",
    "    # Convert image paths to arrays of images\n",
    "    anchor_images = np.array([np.array(Image.open(img_path).resize((224, 224))) for img_path in anchor_images])\n",
    "    positive_images = np.array([np.array(Image.open(img_path).resize((224, 224))) for img_path in positive_images])\n",
    "    negative_images = np.array([np.array(Image.open(img_path).resize((224, 224))) for img_path in negative_images])\n",
    "\n",
    "    # Create the data generator\n",
    "    train_data = tf.data.Dataset.from_tensor_slices((anchor_images, positive_images, negative_images))\n",
    "    train_data = train_data.batch(32)\n",
    "\n",
    "    return train_data\n",
    "\n",
    "\n",
    "# Train the siamese network model\n",
    "def train_siamese_model(siamese_model, train_data):\n",
    "    steps_per_epoch = train_data.samples // train_data.batch_size\n",
    "    history = siamese_model.fit(train_data, steps_per_epoch=steps_per_epoch, epochs=10)\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base model\n",
    "base_model = get_base_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the siamese network model\n",
    "siamese_model = get_siamese_model(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    }
   ],
   "source": [
    "# Compile the siamese network model\n",
    "compile_siamese_model(siamese_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the training dataset\n",
    "train_dir = 'FaceRecognition\\lfw'\n",
    "train_data = get_train_data(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the siamese network model\n",
    "history = train_siamese_model(siamese_model, train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
